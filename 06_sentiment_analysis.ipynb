{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nltk\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc('ps',fonttype = 42)\n",
    "plt.rc('pdf',fonttype = 42)\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.rcParams['ps.useafm'] = True\n",
    "plt.rcParams['pdf.use14corefonts'] = True\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = pd.read_pickle(\"data/processed/texts.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_fix = {\n",
    "    \"Bachiller D. P. Gatell\": \"Bachiller D. P. Gatell.\",\n",
    "    \"Eliza Haywood\": \"Eliza Fowler Haywood\",\n",
    "}\n",
    "texts_df[\"author\"] = texts_df[\"author\"].replace(author_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df[\"language\"] = texts_df[\"language\"].replace(\"Spanish; Castilian\", \"Spanish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From: Chen, Y., & Skiena, S. (2014). Building Sentiment Lexicons for All Major Languages. In ACL (2) (pp. 383-389)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\"German\", \"French\", \"Italian\", \"Spanish\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_lexica = {}\n",
    "for lang in languages:\n",
    "    sentiment_lexica[lang] = {}\n",
    "    with open(\"data/sentiment/negative_words_{}.txt\".format(lang.lower()), \"r\") as fr:\n",
    "        sentiment_lexica[lang][\"neg\"] = fr.read().splitlines()\n",
    "    with open(\"data/sentiment/positive_words_{}.txt\".format(lang.lower()), \"r\") as fr:\n",
    "        sentiment_lexica[lang][\"pos\"] = fr.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in sentiment_lexica.items():\n",
    "    print(k, len(v[\"neg\"]), len(v[\"pos\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text, nl, pl):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    num_negative = 0\n",
    "    num_positive = 0\n",
    "    for nw in nl:\n",
    "        num_negative += tokens.count(nw.lower())\n",
    "    for pw in pl:\n",
    "        num_positive += tokens.count(pw.lower())\n",
    "    try:\n",
    "        score = (num_positive - num_negative) / (num_positive + num_negative)\n",
    "    except ZeroDivisionError:\n",
    "        score = 0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_by_file_df = texts_df.groupby([\"filename\", \"author\", \"language\"])[\"text\"].apply(lambda x: \" \".join(x)).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_by_file_df[\"sentiment\"] = 0\n",
    "for lang in languages:\n",
    "    lang_df = text_by_file_df.loc[text_by_file_df.index.map(lambda x: x[2] == lang)]\n",
    "    neg_lexicon = sentiment_lexica[lang][\"neg\"]\n",
    "    pos_lexicon = sentiment_lexica[lang][\"pos\"]\n",
    "    scores = lang_df[\"text\"].progress_apply(analyze_sentiment, args=[neg_lexicon, pos_lexicon])\n",
    "    \n",
    "    text_by_file_df[\"sentiment\"].update(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_by_file_df[text_by_file_df.index.map(lambda x: x[2] == \"German\")].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = text_by_file_df[text_by_file_df.index.map(lambda x: x[2] in [\"German\", \"Italian\", \"French\", \"Spanish\"])].dropna().groupby(\"language\")[\"sentiment\"].mean().plot(kind=\"bar\", title=\"Sentiment Analysis\")\n",
    "ax.set_ylabel(\"Mean Sentiment Score\")\n",
    "ax.set_xlabel(\"Language\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#plt.savefig(\"sentiment.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = text_by_file_df[text_by_file_df.index.map(lambda x: x[2] in [\"German\", \"Italian\", \"French\", \"Spanish\"])].dropna().groupby(\"author\")[\"sentiment\"].mean().plot(kind=\"bar\", title=\"Sentiment per Author\", figsize=(20, 10))\n",
    "ax.set_ylabel(\"Mean Sentiment Score\")\n",
    "ax.set_xlabel(\"Author\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#plt.savefig(\"sentiment.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_by_file_df[text_by_file_df.index.map(lambda x: x[1] == \"Anonym {Eliza Fowler Haywood}\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_list = [\n",
    "    \"mws-096-297.xml\",\n",
    "\"mws-119-1239.xml\",\n",
    "\"mws-117-1024.xml\",\n",
    "\"mws-099-374.xml\",\n",
    "\"mws-099-375.xml\",\n",
    "\"mws-099-378.xml\",\n",
    "\"mws-099-396.xml\",\n",
    "\"mws-117-1170.xml\",\n",
    "\"mws.3474.xml\",\n",
    "\"mws.3480.xml\",\n",
    "\"mws.5513.xml\",\n",
    "\"mws.5519.xml\",\n",
    "\"mws.5520.xml\",\n",
    "\"mws.5528.xml\",\n",
    "\"mws.5533.xml\",\n",
    "\"mws.5542.xml\",\n",
    "\"mws.5549.xml\",\n",
    "\"mws.5553.xml\",\n",
    "\"mws.5554.xml\",\n",
    "\"mws.5556.xml\",\n",
    "\"mws.5571.xml\",\n",
    "\"mws-099-369.xml\",\n",
    "\"mws-103-473.xml\",\n",
    "\"mws-103-474.xml\",\n",
    "\"mws-103-481.xml\",\n",
    "\"mws-103-487.xml\",\n",
    "\"mws-103-489.xml\",\n",
    "\"mws-103-491.xml\"\n",
    "]\n",
    "\n",
    "\n",
    "negative_list = [\"mws.3464.xml\",\n",
    "\"mws.3466.xml\",\n",
    "\"mws.3468.xml\",\n",
    "\"mws.3470.xml\",\n",
    "\"mws.3478.xml\",\n",
    "\"mws.3482.xml\",\n",
    "\"mws.5512.xml\",\n",
    "\"mws.5514.xml\",\n",
    "\"mws.5517.xml\",\n",
    "\"mws.5518.xml\",\n",
    "\"mws.5521.xml\",\n",
    "\"mws.5526.xml\",\n",
    "\"mws.5530.xml\",\n",
    "\"mws.5534.xml\",\n",
    "\"mws.5536.xml\",\n",
    "\"mws.5537.xml\",\n",
    "\"mws.5540.xml\",\n",
    "\"mws.5544.xml\",\n",
    "\"mws.5545.xml\",\n",
    "\"mws.5555.xml\",\n",
    "\"mws.5587.xml\",\n",
    "\"mws.5590.xml\",\n",
    "\"mws.6347.xml\",\n",
    "\"mws.6349.xml\",\n",
    "\"mws.6351.xml\",\n",
    "\"mws-111-817.xml\",\n",
    "\"mws.2304.xml\",\n",
    "\"mws.7058.xml\",\n",
    "\"mws-099-357.xml\",\n",
    "\"mws-099-358.xml\",\n",
    "\"mws-099-363.xml\",\n",
    "\"mws-099-365.xml\",\n",
    "\"mws-103-463.xml\",\n",
    "\"mws-103-465.xml\",\n",
    "\"mws-103-467.xml\",\n",
    "\"mws-103-488.xml\",\n",
    "\"mws-103-492.xml\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_by_file_df[text_by_file_df.index.map(lambda x: x[0] in negative_list)][\"sentiment\"] - text_by_file_df[text_by_file_df.index.map(lambda x: x[2] == \"Italian\")][\"sentiment\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_by_file_df[text_by_file_df.index.map(lambda x: x[0] in positive_list)][\"sentiment\"] - text_by_file_df[text_by_file_df.index.map(lambda x: x[2] == \"Italian\")][\"sentiment\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_by_file_df[text_by_file_df.index.map(lambda x: x[2] == \"Italian\")][\"sentiment\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_row_df = texts_df[texts_df[\"language\"].isin(languages)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_row_df[\"sentiment\"] = 0\n",
    "for lang in languages:\n",
    "    lang_df = per_row_df.loc[per_row_df[\"language\"] == lang]\n",
    "    neg_lexicon = sentiment_lexica[lang][\"neg\"]\n",
    "    pos_lexicon = sentiment_lexica[lang][\"pos\"]\n",
    "    scores = lang_df[\"text\"].progress_apply(analyze_sentiment, args=[neg_lexicon, pos_lexicon])\n",
    "    \n",
    "    per_row_df[\"sentiment\"].update(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_row_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_row_df.groupby(\"language\")[\"sentiment\"].mean().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_row_df.groupby(\"nde\")[\"sentiment\"].mean().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_row_df.groupby(\"ndf\")[\"sentiment\"].mean().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_row_df[\"date\"] = per_row_df[\"date\"].apply(lambda x: x.split(\"-\")[0])\n",
    "per_row_df[\"date\"] = per_row_df[\"date\"].apply(lambda x: x.split(\" [\")[0])\n",
    "per_row_df[\"date\"] = per_row_df[\"date\"].apply(lambda x: x.split(\" bzw.\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_per_year = per_row_df.groupby(\"date\")[\"sentiment\"].mean()#.plot(figsize=(15, 5))\n",
    "plt.figure(figsize=(15,5))\n",
    "ax = sns.lineplot(x=sent_per_year.index, y=sent_per_year.values)\n",
    "ax.set_xticklabels(sent_per_year.index, rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = per_row_df[\"topics\"].apply(lambda x:pd.Series(list(x))).reset_index().melt(id_vars=\"index\").dropna()[[\"index\", \"value\"]].set_index(\"index\")\n",
    "t_s_df = pd.merge(topics, per_row_df[\"sentiment\"].to_frame(), left_index=True, right_index=True)\n",
    "#per_row_df.groupby(\"date\")[\"topics\"].unique().plot(kind=\"bar\", figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = t_s_df.groupby(\"value\")[\"sentiment\"].mean().plot(kind=\"bar\", figsize=(15, 5))\n",
    "ax.set_xlabel(\"Topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment per topicsover time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_y_df = pd.merge(topics, per_row_df[[\"date\", \"sentiment\"]], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.pivot_table(t_y_df, values=\"sentiment\", index=\"date\", columns=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = table[[\"Idea of Man\", \"Image of Women\", \"Image of Men\", \"Theatre Literature Arts\", \"Manners and Customs\"]].plot(kind=\"line\", legend=True, figsize=(15, 5), xticks=range(0, len(table.index)))\n",
    "ax.set_xticklabels(table.index, rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = per_row_df[\"places\"].apply(lambda x:pd.Series(list(x))).reset_index().melt(id_vars=\"index\").dropna()[[\"index\", \"value\"]].set_index(\"index\")\n",
    "p_s_df = pd.merge(places, per_row_df[[\"sentiment\", \"language\"]], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_s_df[p_s_df[\"value\"] == \"Bristol\"].groupby(\"language\")[\"sentiment\"].mean().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = per_row_df[\"persons\"].apply(lambda x:pd.Series(list(x))).reset_index().melt(id_vars=\"index\").dropna()[[\"index\", \"value\"]].set_index(\"index\")\n",
    "pe_s_df = pd.merge(persons, per_row_df[[\"sentiment\", \"language\"]], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_s_df[pe_s_df[\"value\"] == \"Adonis\"].groupby(\"language\")[\"sentiment\"].mean().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "works = per_row_df[\"works\"].apply(lambda x:pd.Series(list(x))).reset_index().melt(id_vars=\"index\").dropna()[[\"index\", \"value\"]].set_index(\"index\")\n",
    "w_s_df = pd.merge(works, per_row_df[[\"sentiment\", \"language\"]], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_s_df[w_s_df[\"value\"] == \"Macbeth\"].groupby(\"language\")[\"sentiment\"].mean().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
