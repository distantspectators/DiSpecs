{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc('ps',fonttype = 42)\n",
    "plt.rc('pdf',fonttype = 42)\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.rcParams['ps.useafm'] = True\n",
    "plt.rcParams['pdf.use14corefonts'] = True\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = pd.read_pickle(\"data/processed/texts.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_fix = {\n",
    "    \"Bachiller D. P. Gatell\": \"Bachiller D. P. Gatell.\",\n",
    "    \"Eliza Haywood\": \"Eliza Fowler Haywood\",\n",
    "}\n",
    "texts_df[\"author\"] = texts_df[\"author\"].replace(author_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_by_file_df = texts_df.groupby([\"filename\", \"author\", \"language\"])[\"text\"].apply(lambda x: \" \".join(x)).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set.union(*texts_df.groupby(\"filename\")[\"topics\"].agg(lambda x: set.intersection(*x)).tolist())\n",
    "text_by_file_df[\"topics\"] = texts_df.groupby([\"filename\", \"author\", \"language\"])[\"topics\"].agg(lambda x: set.intersection(*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_by_file_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\"German\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, num_top_words):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic {}:\".format(idx))\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-num_top_words - 1:-1]]))\n",
    "        print(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in languages:\n",
    "    lang_texts_df = text_by_file_df.loc[text_by_file_df.index.map(lambda x: x[2] == lang)]\n",
    "    \n",
    "    lang_topics = set.union(*lang_texts_df[\"topics\"])\n",
    "    num_topics = 10#len(lang_topics)\n",
    "    \n",
    "    stop_words = get_stop_words(lang.lower())\n",
    "    \n",
    "    tf_vectorizer = CountVectorizer(max_df=0.8, min_df=2, stop_words=stop_words)\n",
    "    tf = tf_vectorizer.fit_transform(lang_texts_df[\"text\"].tolist())\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    \n",
    "    lda = LatentDirichletAllocation(n_components=num_topics, learning_method=\"online\", learning_offset=50).fit(tf)\n",
    "    \n",
    "    num_top_words = 15\n",
    "    display_topics(lda, tf_feature_names, num_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
