{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nltk\n",
    "import math\n",
    "import spacy\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc('ps',fonttype = 42)\n",
    "plt.rc('pdf',fonttype = 42)\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.rcParams['ps.useafm'] = True\n",
    "plt.rcParams['pdf.use14corefonts'] = True\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = pd.read_pickle(\"data/processed/texts.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_fix = {\n",
    "    \"Bachiller D. P. Gatell\": \"Bachiller D. P. Gatell.\",\n",
    "    \"Eliza Haywood\": \"Eliza Fowler Haywood\",\n",
    "}\n",
    "texts_df[\"author\"] = texts_df[\"author\"].replace(author_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get known authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_authors = texts_df.author.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_authors = []\n",
    "for a in all_authors:\n",
    "    if \"Anonym\" in a or \"Anonyme\" in a or \"An√≥nimo\" in a or \"[\" in a or \"missing\" in a:\n",
    "        continue\n",
    "    known_authors.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_nlp = spacy.load(\"de_core_news_sm\")\n",
    "fr_nlp = spacy.load(\"fr_core_news_sm\")\n",
    "es_nlp = spacy.load(\"es_core_news_sm\")\n",
    "it_nlp = spacy.load(\"it_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_to_use = {\n",
    "    \"German\": de_nlp,\n",
    "    \"French\": fr_nlp,\n",
    "    \"Spanish; Castilian\": es_nlp,\n",
    "    \"Italian\": it_nlp\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_by_file_df = texts_df.groupby([\"filename\", \"author\", \"language\"])[\"text\"].apply(lambda x: \" \".join(x)).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_by_file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokens(row):\n",
    "    lang = row.name[2]\n",
    "    if lang not in nlp_to_use:\n",
    "        return None\n",
    "    doc = nlp_to_use[lang](row[\"text\"])\n",
    "    toks = []\n",
    "    for t in doc:\n",
    "        if any(c.isalpha() for c in t.text):\n",
    "            toks.append((t.text, t.pos_))\n",
    "    return toks\n",
    "    #tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    #return [token for token in tokens if any(c.isalpha() for c in token)]\n",
    "\n",
    "tokens_df = text_by_file_df.progress_apply(create_tokens, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### John Burrows' Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_z_scores(corpus):\n",
    "    # calculate 'standard' freqs\n",
    "    known_authors_freq_dist = list(nltk.FreqDist(corpus.sum()).most_common(100))\n",
    "\n",
    "    # calculate freqs per author\n",
    "    features = [word for word, freq in known_authors_freq_dist]\n",
    "    feature_freqs = {}\n",
    "    for author, tokens in corpus.items():\n",
    "        feature_freqs[author] = {}\n",
    "        overall = len(tokens)\n",
    "        for feature in features:\n",
    "            presence = tokens.count(feature)\n",
    "            feature_freqs[author][feature] = presence / overall\n",
    "        \n",
    "    # calculate means and stds\n",
    "    corpus_features = {}\n",
    "    for feature in features:\n",
    "        corpus_features[feature] = {}\n",
    "\n",
    "        feature_average = 0\n",
    "        for author in corpus.index:\n",
    "            feature_average += feature_freqs[author][feature]\n",
    "        feature_average /= len(corpus.index)\n",
    "        corpus_features[feature][\"Mean\"] = feature_average\n",
    "\n",
    "        feature_stdev = 0\n",
    "        for author in corpus.index:\n",
    "            diff = feature_freqs[author][feature] - corpus_features[feature][\"Mean\"]\n",
    "            feature_stdev += diff*diff\n",
    "        feature_stdev /= (len(corpus.index) - 1)\n",
    "        feature_stdev = math.sqrt(feature_stdev)\n",
    "        corpus_features[feature][\"StdDev\"] = feature_stdev\n",
    "        \n",
    "    # calculate z scores\n",
    "    feature_zscores = {}\n",
    "    for author in corpus.index:\n",
    "        feature_zscores[author] = {}\n",
    "        for feature in features:\n",
    "            feature_val = feature_freqs[author][feature]\n",
    "            feature_mean = corpus_features[feature][\"Mean\"]\n",
    "            feature_stdev = corpus_features[feature][\"StdDev\"]\n",
    "            feature_zscores[author][feature] = ((feature_val-feature_mean) / feature_stdev)\n",
    "    \n",
    "    return features, corpus_features, feature_zscores\n",
    " \n",
    "def calculate_authorship(test_case_tokens, features, corpus_features, feature_zscores, authors):\n",
    "    overall = len(test_case_tokens)\n",
    "    test_case_freqs = {}\n",
    "    for feature in features:\n",
    "        presence = test_case_tokens.count(feature)\n",
    "        test_case_freqs[feature] = presence / overall\n",
    "\n",
    "    test_case_zscores = {}\n",
    "    for feature in features:\n",
    "        feature_val = test_case_freqs[feature]\n",
    "        feature_mean = corpus_features[feature][\"Mean\"]\n",
    "        feature_stdev = corpus_features[feature][\"StdDev\"]\n",
    "        test_case_zscores[feature] = (feature_val - feature_mean) / feature_stdev\n",
    "        #print(\"Test case z-score for feature\", feature, \"is\", test_case_zscores[feature])\n",
    "    \n",
    "    lowest_delta = None\n",
    "    for author in authors:\n",
    "        delta = 0\n",
    "        for feature in features:\n",
    "            delta += math.fabs((test_case_zscores[feature] - feature_zscores[author][feature]))\n",
    "        delta /= len(features)\n",
    "        if lowest_delta is None or delta < lowest_delta:\n",
    "            lowest_delta = delta\n",
    "            pred_author = author\n",
    "    return pred_author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\"German\", \"French\", \"Italian\", \"Spanish; Castilian\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "for lang in languages:\n",
    "    test_results[lang] = {}\n",
    "    # reduce tokens dataframe to current language\n",
    "    lang_tokens_df = tokens_df.loc[tokens_df.index.map(lambda x: x[2] == lang)]\n",
    "    \n",
    "    # reduce to known authors\n",
    "    known_authors_tokens_df = lang_tokens_df.loc[lang_tokens_df.index.map(lambda x: x[1] in known_authors)]\n",
    "    \n",
    "    # extract test cases\n",
    "    test_cases_per_author = known_authors_tokens_df.groupby(\"author\").size().apply(lambda x: min(x - 1, 5))\n",
    "    test_cases = []\n",
    "    for a, n in test_cases_per_author.items():\n",
    "        if n > 0:\n",
    "            test_cases.append(known_authors_tokens_df.loc[known_authors_tokens_df.index.map(lambda x: x[1] == a and x[2] == lang)].sample(n))\n",
    "    test_cases_df = pd.concat(test_cases)\n",
    "    print(\"found {} testcases out of {}\".format(len(test_cases_df), len(known_authors_tokens_df)))\n",
    "\n",
    "    # calculate authorship for test cases\n",
    "    \n",
    "    for tc in tqdm(test_cases_df.iteritems(), total=len(test_cases_df)):\n",
    "        # group by author\n",
    "        known_authors_combined_tokens_df = known_authors_tokens_df.drop(tc[0]).groupby(\"author\").sum()\n",
    "        \n",
    "        # calc z-scores\n",
    "        features, corpus_features, feature_zscores = calculate_z_scores(known_authors_combined_tokens_df)\n",
    "        \n",
    "        # calc authorship\n",
    "        pred_author = calculate_authorship(tc[1], features, corpus_features, feature_zscores, known_authors_combined_tokens_df.index)\n",
    "        test_results[lang][tc[0]] = pred_author\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results = pd.Series()\n",
    "for lang in languages:\n",
    "    num_correct = 0\n",
    "    for i, v in test_results[lang].items():\n",
    "        if i[1] == v:\n",
    "            num_correct += 1\n",
    "    ratio_correct = num_correct / len(test_results[lang])\n",
    "    plot_results[lang] = ratio_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_results.plot(kind=\"bar\", title=\"Stylometry Performance\", figsize=(5, 5))\n",
    "ax.set_ylabel(\"Ratio of Correctly Detected Authorship\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"stylometry.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect anonymous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_anonymous_df = text_by_file_df.loc[text_by_file_df.index.map(lambda x: x[1] == \"Anonym\")].copy()\n",
    "all_anonymous_df[\"probable_author\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\"German\", \"French\", \"Italian\", \"Spanish; Castilian\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_results = {}\n",
    "for lang in languages:\n",
    "    # reduce tokens dataframe to current language\n",
    "    lang_tokens_df = tokens_df.loc[text_by_file_df.index.map(lambda x: x[2] == lang)]\n",
    "    \n",
    "    # reduce to known authors\n",
    "    known_authors_tokens_df = lang_tokens_df.loc[lang_tokens_df.index.map(lambda x: x[1] in known_authors)]\n",
    "    \n",
    "    # group by author\n",
    "    known_authors_combined_tokens_df = known_authors_tokens_df.groupby(\"author\").sum()\n",
    "    \n",
    "    # calcualte z-scores\n",
    "    features, corpus_features, feature_zscores = calculate_z_scores(known_authors_combined_tokens_df)\n",
    "    \n",
    "    # get anonymous works\n",
    "    anonymous_authors_tokens_df = lang_tokens_df.loc[lang_tokens_df.index.map(lambda x: x[1] == \"Anonym\")]\n",
    "    \n",
    "    # calc authorship for anonymous work\n",
    "    for uw in tqdm(anonymous_authors_tokens_df.iteritems(), total=len(anonymous_authors_tokens_df)):\n",
    "        pred_author = calculate_authorship(uw[1], features, corpus_features, feature_zscores, known_authors_combined_tokens_df.index)\n",
    "        detection_results[uw[0]] = pred_author\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in detection_results.items():\n",
    "    all_anonymous_df.loc[i, \"probable_author\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_anonymous_df.loc[(\" \", \"Anonym\", \"Spanish; Castilian\"),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
